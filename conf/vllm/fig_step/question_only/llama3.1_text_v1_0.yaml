defaults:
  - hydra: default
  - _self_

hydra:
  searchpath:
    - file://conf/


data_dir: ../research.data/mm-safety/
train_file:
dev_file:
test_file: ${data_dir}/FigStep/data/question/safebench.csv

port: 6000
model: Meta-Llama-3.1-8B-Instruct

sampling_params:
  _target_: vllm.SamplingParams
  n: 1
  temperature: 0.0
  stop: [ "</s>", "\n\n\n\n", "Context:\n", "Thought 42:", "<|end_of_text|>", "<|eot_id|>", "<|EOT|>" ]
  max_tokens: 512

tem: ${sampling_params.temperature}
n: ${sampling_params.n}
split_size: -1
split_id: 0
max_num_seqs: 256
suffix: n${n}.tem${tem}

output_file: outputs/${model}/fig-step/fig-step.text-only.${suffix}.json
flush_file: ${output_file}l

apply_chat_template: False
add_generation_prompt: True


prompt: "{question}"
chat_prefix: "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful assistant to answer the questions from the user.<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n"
chat_suffix: "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n"

# Data loading
read_tensor:
  _target_: dataset.combine_dataset.ResponseAlignDataset
  read_fn:
    _target_: dataset.readers.SafeBenchCSVReader.return_cls
    image_dir: ${data_dir}/FigStep/data/images/SafeBench
    image_name_template: "query_ForbidQI_{category_id}_{task_id}_6.png"
  template: ${chat_prefix}${prompt}${chat_suffix}
  instruction:
  index_field: "id"
  service_based: True
  service_processor:
    _target_: dataset.vllm.VLLMRequestGenerator
    api_url: http://0.0.0.0:${port}/v1/completions
    max_tokens: ${sampling_params.max_tokens}
    model: ${model}
    stop: ${sampling_params.stop}
    n: ${n}
    temperature: ${tem}
    top_p: ${top_p}
  split_size: ${split_size}
  split_id: ${split_id}
  max_data_num: -1

save_best: True
eval_sub_path:
output_dir: ../pretrained-models/Meta-Llama-3.1-8B-Instruct

# Dataloader
num_workers: 32
prefetch_factor: 2

dp_size:
tp_size: 1
pp_size: 1

post_process:
  _target_: post_processors.api_callback.SafetyResponseCallback
  answer_clean:
  evaluator:
    _target_: post_processors.eval.keywords.KeyWordsEvaluator
  output_file: ${output_file}
  index_field: id
  saved_keys: [ "dataset", "category_id", "task_id", "category", "question", "instruction" ]

# Training hyper-parameters
per_gpu_train_batch_size: 1
per_gpu_eval_batch_size: 1

ddp_eval: False
no_cuda: False
seed: 42
local_rank: -1

# Temporary variables
fp16: True
fp16_bfloat16: True
n_gpu: 1
device:
train_batch_size:
eval_batch_size:
world_size: